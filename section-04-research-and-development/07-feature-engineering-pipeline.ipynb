{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering with in house software\n",
    "\n",
    "In this notebook, we will set up all the feature engineering steps within a Scikit-learn pipeline utilizing the open source transformers plus those we developed in house."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reproducibility: Setting the seed\n",
    "\n",
    "With the aim to ensure reproducibility between runs of the same notebook, but also between the research and production environment, for each step that includes some element of randomness, it is extremely important that we **set the seed**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data manipulation and plotting\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# for saving the pipeline\n",
    "import joblib\n",
    "\n",
    "# from Scikit-learn\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import MinMaxScaler, Binarizer\n",
    "\n",
    "# from feature-engine\n",
    "from feature_engine.imputation import (\n",
    "    AddMissingIndicator,\n",
    "    MeanMedianImputer,\n",
    "    CategoricalImputer,\n",
    ")\n",
    "\n",
    "from feature_engine.encoding import (\n",
    "    RareLabelEncoder,\n",
    "    OrdinalEncoder,\n",
    ")\n",
    "\n",
    "from feature_engine.transformation import (\n",
    "    LogTransformer,\n",
    "    YeoJohnsonTransformer,\n",
    ")\n",
    "\n",
    "from feature_engine.selection import DropFeatures\n",
    "from feature_engine.wrappers import SklearnTransformerWrapper\n",
    "\n",
    "import preprocessors as pp\n",
    "\n",
    "# to visualise al the columns in the dataframe\n",
    "pd.pandas.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load dataset\n",
    "data = pd.read_csv('/media/gromovnik/Vice_SSD/01. Projects/03. Courses/Udemy_Deployment_Of_ML_Models/dataset/house-prices-advanced-regression-techniques/train.csv')\n",
    "\n",
    "# rows and columns of the data\n",
    "print(data.shape)\n",
    "\n",
    "# visualise the dataset\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cast MSSubClass as object\n",
    "\n",
    "data['MSSubClass'] = data['MSSubClass'].astype('O')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Separate dataset into train and test\n",
    "\n",
    "It is important to separate our data intro training and testing set. \n",
    "\n",
    "When we engineer features, some techniques learn parameters from data. It is important to learn these parameters only from the train set. This is to avoid over-fitting.\n",
    "\n",
    "Our feature engineering techniques will learn:\n",
    "\n",
    "- mean\n",
    "- mode\n",
    "- exponents for the yeo-johnson\n",
    "- category frequency\n",
    "- and category to number mappings\n",
    "\n",
    "from the train set.\n",
    "\n",
    "**Separating the data into train and test involves randomness, therefore, we need to set the seed.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's separate into train and test set\n",
    "# Remember to set the seed (random_state for this sklearn function)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    data.drop(['Id', 'SalePrice'], axis=1), # predictive variables\n",
    "    data['SalePrice'], # target\n",
    "    test_size=0.1, # portion of dataset to allocate to test set\n",
    "    random_state=0, # we are setting the seed here\n",
    ")\n",
    "\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Target\n",
    "\n",
    "We apply the logarithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = np.log(y_train)\n",
    "y_test = np.log(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# categorical variables with NA in train set\n",
    "CATEGORICAL_VARS_WITH_NA_FREQUENT = ['MasVnrType',\n",
    "                                     'BsmtQual',\n",
    "                                     'BsmtCond',\n",
    "                                     'BsmtExposure',\n",
    "                                     'BsmtFinType1',\n",
    "                                     'BsmtFinType2',\n",
    "                                     'Electrical',\n",
    "                                     'GarageType',\n",
    "                                     'GarageFinish',\n",
    "                                     'GarageQual',\n",
    "                                     'GarageCond']\n",
    "\n",
    "\n",
    "CATEGORICAL_VARS_WITH_NA_MISSING = [\n",
    "    'Alley', 'FireplaceQu', 'PoolQC', 'Fence', 'MiscFeature']\n",
    "\n",
    "\n",
    "# numerical variables with NA in train set\n",
    "NUMERICAL_VARS_WITH_NA = ['LotFrontage', 'MasVnrArea', 'GarageYrBlt']\n",
    "\n",
    "\n",
    "TEMPORAL_VARS = ['YearBuilt', 'YearRemodAdd', 'GarageYrBlt']\n",
    "REF_VAR = \"YrSold\"\n",
    "\n",
    "\n",
    "# variables to log transform\n",
    "NUMERICALS_LOG_VARS = [\"LotFrontage\", \"1stFlrSF\", \"GrLivArea\"]\n",
    "\n",
    "NUMERICALS_YEO_VARS = ['LotArea']\n",
    "\n",
    "\n",
    "BINARIZE_VARS = [\n",
    "    'BsmtFinSF2', 'LowQualFinSF', 'EnclosedPorch',\n",
    "    '3SsnPorch', 'ScreenPorch', 'MiscVal'\n",
    "]\n",
    "\n",
    "# variables to map\n",
    "QUAL_VARS = ['ExterQual', 'ExterCond', 'BsmtQual', 'BsmtCond',\n",
    "             'HeatingQC', 'KitchenQual', 'FireplaceQu',\n",
    "             'GarageQual', 'GarageCond',\n",
    "             ]\n",
    "\n",
    "EXPOSURE_VARS = ['BsmtExposure']\n",
    "\n",
    "FINISH_VARS = ['BsmtFinType1', 'BsmtFinType2']\n",
    "\n",
    "GARAGE_VARS = ['GarageFinish']\n",
    "\n",
    "FENCE_VARS = ['Fence']\n",
    "\n",
    "# categorical variables to encode\n",
    "CATEGORICAL_VARS = [\n",
    "    'MSZoning',\n",
    "    'Street',\n",
    "    'Alley',\n",
    "    'LotShape',\n",
    "    'LandContour',\n",
    "    'Utilities',\n",
    "    'LotConfig',\n",
    "    'LandSlope',\n",
    "    'Neighborhood',\n",
    "    'Condition1',\n",
    "    'Condition2',\n",
    "    'BldgType',\n",
    "    'HouseStyle',\n",
    "    'RoofStyle',\n",
    "    'RoofMatl',\n",
    "    'Exterior1st',\n",
    "    'Exterior2nd',\n",
    "    'MasVnrType',\n",
    "    'Foundation',\n",
    "    'Heating',\n",
    "    'CentralAir',\n",
    "    'Electrical',\n",
    "    'Functional',\n",
    "    'GarageType',\n",
    "    'PavedDrive',\n",
    "    'PoolQC',\n",
    "    'MiscFeature',\n",
    "    'SaleType',\n",
    "    'SaleCondition',\n",
    "    'MSSubClass']\n",
    "\n",
    "\n",
    "QUAL_MAPPINGS = {'Po': 1, 'Fa': 2, 'TA': 3,\n",
    "                 'Gd': 4, 'Ex': 5, 'Missing': 0, 'NA': 0}\n",
    "\n",
    "EXPOSURE_MAPPINGS = {'No': 1, 'Mn': 2, 'Av': 3, 'Gd': 4}\n",
    "\n",
    "FINISH_MAPPINGS = {'Missing': 0, 'NA': 0, 'Unf': 1,\n",
    "                   'LwQ': 2, 'Rec': 3, 'BLQ': 4, 'ALQ': 5, 'GLQ': 6}\n",
    "\n",
    "GARAGE_MAPPINGS = {'Missing': 0, 'NA': 0, 'Unf': 1, 'RFn': 2, 'Fin': 3}\n",
    "\n",
    "FENCE_MAPPINGS = {'Missing': 0, 'NA': 0,\n",
    "                  'MnWw': 1, 'GdWo': 2, 'MnPrv': 3, 'GdPrv': 4}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipeline - Feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up the pipeline\n",
    "price_pipe = Pipeline([\n",
    "\n",
    "    # ===== IMPUTATION =====\n",
    "    # impute categorical variables with string missing\n",
    "    ('missing_imputation', CategoricalImputer(\n",
    "        imputation_method='missing', variables=CATEGORICAL_VARS_WITH_NA_MISSING)),\n",
    "\n",
    "    ('frequent_imputation', CategoricalImputer(\n",
    "        imputation_method='frequent', variables=CATEGORICAL_VARS_WITH_NA_FREQUENT)),\n",
    "\n",
    "    # add missing indicator\n",
    "    ('missing_indicator', AddMissingIndicator(variables=NUMERICAL_VARS_WITH_NA)),\n",
    "\n",
    "    # impute numerical variables with the mean\n",
    "    ('mean_imputation', MeanMedianImputer(\n",
    "        imputation_method='mean', variables=NUMERICAL_VARS_WITH_NA\n",
    "    )),\n",
    "    \n",
    "    \n",
    "    # == TEMPORAL VARIABLES ====\n",
    "    ('elapsed_time', pp.TemporalVariableTransformer(\n",
    "        variables=TEMPORAL_VARS, reference_variable=REF_VAR)),\n",
    "\n",
    "    ('drop_features', DropFeatures(features_to_drop=[REF_VAR])),\n",
    "\n",
    "   \n",
    "\n",
    "    # ==== VARIABLE TRANSFORMATION =====\n",
    "    ('log', LogTransformer(variables=NUMERICALS_LOG_VARS)),\n",
    "    \n",
    "    ('yeojohnson', YeoJohnsonTransformer(variables=NUMERICALS_YEO_VARS)),\n",
    "    \n",
    "    ('binarizer', SklearnTransformerWrapper(\n",
    "        transformer=Binarizer(threshold=0), variables=BINARIZE_VARS)),\n",
    "    \n",
    "\n",
    "    # === mappers ===\n",
    "    ('mapper_qual', pp.Mapper(\n",
    "        variables=QUAL_VARS, mappings=QUAL_MAPPINGS)),\n",
    "\n",
    "    ('mapper_exposure', pp.Mapper(\n",
    "        variables=EXPOSURE_VARS, mappings=EXPOSURE_MAPPINGS)),\n",
    "\n",
    "    ('mapper_finish', pp.Mapper(\n",
    "        variables=FINISH_VARS, mappings=FINISH_MAPPINGS)),\n",
    "\n",
    "    ('mapper_garage', pp.Mapper(\n",
    "        variables=GARAGE_VARS, mappings=GARAGE_MAPPINGS)),\n",
    "    \n",
    "    ('mapper_fence', pp.Mapper(\n",
    "        variables=FENCE_VARS, mappings=FENCE_MAPPINGS)),\n",
    "\n",
    "\n",
    "    # == CATEGORICAL ENCODING\n",
    "    ('rare_label_encoder', RareLabelEncoder(\n",
    "        tol=0.01, n_categories=1, variables=CATEGORICAL_VARS\n",
    "    )),\n",
    "\n",
    "    # encode categorical and discrete variables using the target mean\n",
    "    ('categorical_encoder', OrdinalEncoder(\n",
    "        encoding_method='ordered', variables=CATEGORICAL_VARS)),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train the pipeline\n",
    "price_pipe.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = price_pipe.transform(X_train)\n",
    "X_test = price_pipe.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check absence of na in the train set\n",
    "[var for var in X_train.columns if X_train[var].isnull().sum() > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check absence of na in the test set\n",
    "[var for var in X_test.columns if X_test[var].isnull().sum() > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# the parameters are learnt and stored in each step\n",
    "# of the pipeline\n",
    "\n",
    "price_pipe.named_steps['frequent_imputation'].imputer_dict_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "\n",
    "Now we have all the feature engineering steps in 1 pipeline.\n",
    "\n",
    "The next steps are:\n",
    "\n",
    "- Add the scaler and model to the pipeline\n",
    "- Produce a final pipeline only with the selected features"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "course",
   "language": "python",
   "name": "course"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "583px",
    "left": "0px",
    "right": "1324px",
    "top": "107px",
    "width": "212px"
   },
   "toc_section_display": "block",
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predicting Survival on the Titanic\n",
    "\n",
    "### History\n",
    "Perhaps one of the most infamous shipwrecks in history, the Titanic sank after colliding with an iceberg, killing 1502 out of 2224 people on board. Interestingly, by analysing the probability of survival based on few attributes like gender, age, and social status, we can make very accurate predictions on which passengers would survive. Some groups of people were more likely to survive than others, such as women, children, and the upper-class. Therefore, we can learn about the society priorities and privileges at the time.\n",
    "\n",
    "### Assignment:\n",
    "\n",
    "Build a Machine Learning Pipeline, to engineer the features in the data set and predict who is more likely to Survive the catastrophe.\n",
    "\n",
    "Follow the Jupyter notebook below, and complete the missing bits of code, to achieve each one of the pipeline steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "# to handle datasets\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# for visualization\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# to divide train and test set\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# feature scaling\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# to build the models\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# to evaluate the models\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "\n",
    "# to persist the model and the scaler\n",
    "import joblib\n",
    "\n",
    "# to visualise al the columns in the dataframe\n",
    "pd.pandas.set_option('display.max_columns', None)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare the data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the data - it is available open source and online\n",
    "\n",
    "data = pd.read_csv('https://www.openml.org/data/get_csv/16826755/phpMYEkMl')\n",
    "\n",
    "# display data\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace interrogation marks by NaN values\n",
    "\n",
    "data = data.replace('?', np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# retain only the first cabin if more than\n",
    "# 1 are available per passenger\n",
    "\n",
    "def get_first_cabin(row):\n",
    "    try:\n",
    "        return row.split()[0]\n",
    "    except:\n",
    "        return np.nan\n",
    "    \n",
    "data['cabin'] = data['cabin'].apply(get_first_cabin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extracts the title (Mr, Ms, etc) from the name variable\n",
    "\n",
    "def get_title(passenger):\n",
    "    line = passenger\n",
    "    if re.search('Mrs', line):\n",
    "        return 'Mrs'\n",
    "    elif re.search('Mr', line):\n",
    "        return 'Mr'\n",
    "    elif re.search('Miss', line):\n",
    "        return 'Miss'\n",
    "    elif re.search('Master', line):\n",
    "        return 'Master'\n",
    "    else:\n",
    "        return 'Other'\n",
    "    \n",
    "data['title'] = data['name'].apply(get_title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cast numerical variables as floats\n",
    "\n",
    "data['fare'] = data['fare'].astype('float')\n",
    "data['age'] = data['age'].astype('float')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop unnecessary variables\n",
    "\n",
    "data.drop(labels=['name','ticket', 'boat', 'body','home.dest'], axis=1, inplace=True)\n",
    "\n",
    "# display data\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the data set\n",
    "data.to_csv('titanic.csv', index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Exploration\n",
    "\n",
    "### Find numerical and categorical variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = 'survived'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vars_num = [var for var in data.columns if data[var].dtype != 'O' and var != 'survived']\n",
    "vars_cat = [var for var in data.columns if data[var].dtype == 'O']\n",
    "\n",
    "print('Number of numerical variables: {}'.format(len(vars_num)))\n",
    "print('Number of categorical variables: {}'.format(len(vars_cat)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(vars_num)\n",
    "print(vars_cat)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find missing values in variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a list of the variables that contain missing values\n",
    "vars_with_na = [var for var in data.columns if data[var].isnull().sum() > 0]\n",
    "\n",
    "# determine percentage of missing values (expressed as decimals)\n",
    "# and display the result ordered by % of missing data\n",
    "data[vars_with_na].isnull().mean().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first in numerical variables\n",
    "num_na = [var for var in vars_num if var in vars_with_na]\n",
    "print(num_na)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now in categorical variables\n",
    "cat_na = [var for var in vars_cat if var in vars_with_na]\n",
    "print(cat_na)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Determine cardinality of categorical variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[vars_cat].nunique().sort_values(ascending=False).plot.bar(figsize=(12,5))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Determine the distribution of numerical variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[vars_num].hist(bins=30, figsize=(15,15))\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Separate data into train and test\n",
    "\n",
    "Use the code below for reproducibility. Don't change it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    data.drop('survived', axis=1),  # predictors\n",
    "    data['survived'],  # target\n",
    "    test_size=0.2,  # percentage of obs in test set\n",
    "    random_state=0)  # seed to ensure reproducibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.shape, y_test.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering\n",
    "\n",
    "### Extract only the letter (and drop the number) from the variable Cabin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train['cabin'] = X_train['cabin'].str[0]\n",
    "X_test['cabin'] = X_test['cabin'].str[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check\n",
    "print(X_train.shape)\n",
    "print(X_train['cabin'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fill in Missing data in numerical variables:\n",
    "\n",
    "- Add a binary missing indicator\n",
    "- Fill NA in original variable with the median"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for var in num_na:\n",
    "    # calculate the median using the train set\n",
    "    median_val = X_train[var].median()\n",
    "    print(var, median_val)\n",
    "\n",
    "    # add binary missing indicator (in train and test)\n",
    "    X_train[var + '_na'] = np.where(X_train[var].isnull(), 1, 0)\n",
    "    X_test[var + '_na'] = np.where(X_test[var].isnull(), 1, 0)\n",
    "\n",
    "    # replace missing values by the mean\n",
    "    # (in train and test)\n",
    "    X_train[var].fillna(median_val, inplace=True)\n",
    "    X_test[var].fillna(median_val, inplace=True)\n",
    "\n",
    "# check that we have no more missing values in the engineered variables\n",
    "X_train[num_na].isnull().sum()\n",
    "X_test[num_na].isnull().sum()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Replace Missing data in categorical variables with the string **Missing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for var in cat_na:\n",
    "    X_train[cat_na] = X_train[cat_na].fillna('Missing')\n",
    "    X_test[cat_na] = X_test[cat_na].fillna('Missing')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check\n",
    "print(X_train[cat_na])\n",
    "print(X_test[cat_na])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove rare labels in categorical variables\n",
    "\n",
    "- remove labels present in less than 5 % of the passengers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_less_frequent_labels(df, var, rare_perc):\n",
    "    \n",
    "    # function finds the labels that are shared by less than\n",
    "    # a certain % of the rows in the dataset\n",
    "    # returns pandas.Index type\n",
    "\n",
    "    df = df.copy()\n",
    "\n",
    "    tmp = df.groupby(var)[var].count() / len(df)\n",
    "\n",
    "    return tmp[tmp < rare_perc].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for var in vars_cat:\n",
    "    # find the less_frequent labels\n",
    "    less_frequent_ls = find_less_frequent_labels(X_train, var, 0.05)\n",
    "    \n",
    "    print(var, less_frequent_ls)\n",
    "    print()\n",
    "    train_mask = X_train[var].isin(less_frequent_ls)\n",
    "    test_mask = X_test[var].isin(less_frequent_ls)\n",
    "    # keep only frequent labels\n",
    "    X_train = X_train[train_mask == False]\n",
    "    X_test = X_test[test_mask == False]\n",
    "    \n",
    "    # remove corresponding target rows\n",
    "    y_train = y_train[train_mask == False]\n",
    "    y_test = y_test[test_mask == False]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perform one hot encoding of categorical variables into k-1 binary variables\n",
    "\n",
    "- k-1, means that if the variable contains 9 different categories, we create 8 different binary variables\n",
    "- Remember to drop the original categorical variable (the one with the strings) after the encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for var in vars_cat:\n",
    "    unique_labels = X_train[var].unique()\n",
    "    one_hot_labels = np.arange(X_train[var].nunique())\n",
    "    mapping = dict(zip(unique_labels, one_hot_labels))\n",
    "    \n",
    "    X_train[var] = X_train[var].map(mapping)\n",
    "    X_train[var] = X_train[var].astype('int64')\n",
    "    \n",
    "    unique_labels = X_test[var].unique()\n",
    "    one_hot_labels = np.arange(X_test[var].nunique())\n",
    "    mapping = dict(zip(unique_labels, one_hot_labels))\n",
    "    \n",
    "    X_test[var] = X_test[var].map(mapping)\n",
    "    X_test[var] = X_test[var].astype('int64')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scale the variables\n",
    "\n",
    "- Use the standard scaler from Scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "X_train = pd.DataFrame(\n",
    "    scaler.transform(X_train),\n",
    "    columns=X_train.columns\n",
    ")\n",
    "\n",
    "X_test = pd.DataFrame(\n",
    "    scaler.transform(X_test),\n",
    "    columns=X_train.columns\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the Logistic Regression model\n",
    "\n",
    "- Set the regularization parameter to 0.0005\n",
    "- Set the seed to 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_reg_model = LogisticRegression(C=2000.0, random_state=0)\n",
    "log_reg_model.fit(X_train, y_train)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make predictions and evaluate model performance\n",
    "\n",
    "Determine:\n",
    "- roc-auc\n",
    "- accuracy\n",
    "\n",
    "**Important, remember that to determine the accuracy, you need the outcome 0, 1, referring to survived or not. But to determine the roc-auc you need the probability of survival.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training dataset\n",
    "pred = log_reg_model.predict(X_train)\n",
    "pred_prob = log_reg_model.predict_proba(X_train)\n",
    "print('train accuracy: ', accuracy_score(y_train, pred))\n",
    "print('train roc-auc score ', roc_auc_score(y_train, pred_prob[:, 1]))\n",
    "\n",
    "# testing dataset\n",
    "pred = log_reg_model.predict(X_test)\n",
    "pred_prob = log_reg_model.predict_proba(X_test)\n",
    "print('test accuracy: ', accuracy_score(y_test, pred))\n",
    "print('test roc-auc score ', roc_auc_score(y_test, pred_prob[:, 1]))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's it! Well done\n",
    "\n",
    "**Keep this code safe, as we will use this notebook later on, to build production code, in our next assignement!!**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "course",
   "language": "python",
   "name": "course"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

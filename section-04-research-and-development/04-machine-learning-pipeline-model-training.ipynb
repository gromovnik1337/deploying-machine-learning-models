{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning Pipeline - Model Training\n",
    "\n",
    "In this notebook, we pick up the transformed datasets and the selected variables that we saved in the previous notebooks."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reproducibility: Setting the seed\n",
    "\n",
    "With the aim to ensure reproducibility between runs of the same notebook, but also between the research and production environment, for each step that includes some element of randomness, it is extremely important that we **set the seed**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to handle datasets\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# for plotting\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# to save the model\n",
    "import joblib\n",
    "\n",
    "# to build the model\n",
    "from sklearn.linear_model import Lasso\n",
    "\n",
    "# to evaluate the model\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# to visualise al the columns in the dataframe\n",
    "pd.pandas.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the train and test set with the engineered variables\n",
    "\n",
    "# we built and saved these datasets in a previous notebook.\n",
    "# If you haven't done so, go ahead and check the previous notebooks (step 2)\n",
    "# to find out how to create these datasets\n",
    "\n",
    "X_train = pd.read_csv('/media/vice/vice_SSD/01. Projects/03. Courses/Udemy_Deployment_Of_ML_Models/dataset/xtrain.csv')\n",
    "X_test = pd.read_csv('/media/vice/vice_SSD/01. Projects/03. Courses/Udemy_Deployment_Of_ML_Models/dataset/xtest.csv')\n",
    "\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the target (remember that the target is log transformed)\n",
    "y_train = pd.read_csv('/media/vice/vice_SSD/01. Projects/03. Courses/Udemy_Deployment_Of_ML_Models/dataset/ytrain.csv')\n",
    "y_test = pd.read_csv('/media/vice/vice_SSD/01. Projects/03. Courses/Udemy_Deployment_Of_ML_Models/dataset/ytest.csv')\n",
    "\n",
    "y_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the pre-selected features\n",
    "# ==============================\n",
    "\n",
    "# we selected the features in the previous notebook (step 3)\n",
    "\n",
    "# if you haven't done so, go ahead and visit the previous notebook\n",
    "# to find out how to select the features\n",
    "\n",
    "features = pd.read_csv('/media/vice/vice_SSD/01. Projects/03. Courses/Udemy_Deployment_Of_ML_Models/dataset/selected_features.csv')\n",
    "features = features['0'].to_list() \n",
    "\n",
    "# display final feature set\n",
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reduce the train and test set to the selected features\n",
    "\n",
    "X_train = X_train[features]\n",
    "X_test = X_test[features]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regularised linear regression: Lasso\n",
    "\n",
    "Remember to set the seed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up the model\n",
    "# remember to set the random_state / seed\n",
    "\n",
    "lin_model = Lasso(alpha=0.001, random_state=0)\n",
    "\n",
    "# train the model\n",
    "\n",
    "lin_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate the model:\n",
    "# ====================\n",
    "\n",
    "# remember that we log transformed the output (SalePrice)\n",
    "# in our feature engineering notebook (step 2).\n",
    "\n",
    "# In order to get the true performance of the Lasso\n",
    "# we need to transform both the target and the predictions\n",
    "# back to the original house prices values.\n",
    "\n",
    "# We will evaluate performance using the mean squared error and\n",
    "# the root of the mean squared error and r2\n",
    "\n",
    "# make predictions for train set\n",
    "pred = lin_model.predict(X_train)\n",
    "\n",
    "# determine mse, rmse and r2\n",
    "print('train mse: {}'.format(int(\n",
    "    mean_squared_error(np.exp(y_train), np.exp(pred)))))\n",
    "print('train rmse: {}'.format(int(\n",
    "    mean_squared_error(np.exp(y_train), np.exp(pred), squared=False))))\n",
    "print('train r2: {}'.format(\n",
    "    r2_score(np.exp(y_train), np.exp(pred))))\n",
    "print()\n",
    "\n",
    "# make predictions for test set\n",
    "pred = lin_model.predict(X_test)\n",
    "\n",
    "# determine mse, rmse and r2\n",
    "print('test mse: {}'.format(int(\n",
    "    mean_squared_error(np.exp(y_test), np.exp(pred)))))\n",
    "print('test rmse: {}'.format(int(\n",
    "    mean_squared_error(np.exp(y_test), np.exp(pred), squared=False))))\n",
    "print('test r2: {}'.format(\n",
    "    r2_score(np.exp(y_test), np.exp(pred))))\n",
    "print()\n",
    "\n",
    "print('Average house price: ', int(np.exp(y_train).median()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's evaluate our predictions respect to the real sale price\n",
    "plt.scatter(y_test, lin_model.predict(X_test))\n",
    "plt.xlabel('True House Price')\n",
    "plt.ylabel('Predicted House Price')\n",
    "plt.title('Evaluation of Lasso Predictions')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that our model is doing a pretty good job at estimating house prices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's evaluate the distribution of the errors: \n",
    "# they should be fairly normally distributed\n",
    "\n",
    "y_test.reset_index(drop=True, inplace=True)\n",
    "\n",
    "preds = pd.Series(lin_model.predict(X_test))\n",
    "\n",
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's evaluate the distribution of the errors: \n",
    "# they should be fairly normally distributed\n",
    "\n",
    "errors = y_test['SalePrice'] - preds\n",
    "errors.hist(bins=30)\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The distribution of the errors follows quite closely a gaussian distribution. That suggests that our model is doing a good job as well."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finally, just for fun, let's look at the feature importance\n",
    "\n",
    "importance = pd.Series(np.abs(lin_model.coef_.ravel()))\n",
    "importance.index = features\n",
    "importance.sort_values(inplace=True, ascending=False)\n",
    "importance.plot.bar(figsize=(18,6))\n",
    "plt.ylabel('Lasso Coefficients')\n",
    "plt.title('Feature Importance')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we are happy to our model, so we save it to be able\n",
    "# to score new data\n",
    "\n",
    "joblib.dump(lin_model, '/media/vice/vice_SSD/01. Projects/03. Courses/Udemy_Deployment_Of_ML_Models/saved_pipelines/linear_regression.joblib') "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Additional Resources\n",
    "\n",
    "\n",
    "## Feature Engineering\n",
    "\n",
    "- [Feature Engineering for Machine Learning](https://www.udemy.com/course/feature-engineering-for-machine-learning/?referralCode=A855148E05283015CF06) - Online Course\n",
    "- [Packt Feature Engineering Cookbook](https://www.packtpub.com/data/python-feature-engineering-cookbook) - Book\n",
    "- [Feature Engineering for Machine Learning: A comprehensive Overview](https://trainindata.medium.com/feature-engineering-for-machine-learning-a-comprehensive-overview-a7ad04c896f8) - Article\n",
    "- [Practical Code Implementations of Feature Engineering for Machine Learning with Python](https://towardsdatascience.com/practical-code-implementations-of-feature-engineering-for-machine-learning-with-python-f13b953d4bcd) - Article\n",
    "\n",
    "## Feature Selection\n",
    "\n",
    "- [Feature Selection for Machine Learning](https://www.udemy.com/course/feature-selection-for-machine-learning/?referralCode=186501DF5D93F48C4F71) - Online Course\n",
    "- [Feature Selection for Machine Learning: A comprehensive Overview](https://trainindata.medium.com/feature-selection-for-machine-learning-a-comprehensive-overview-bd571db5dd2d) - Article\n",
    "\n",
    "## Machine Learning\n",
    "\n",
    "- [Best Resources to Learn Machine Learning](https://trainindata.medium.com/find-out-the-best-resources-to-learn-machine-learning-cd560beec2b7) - Article\n",
    "- [Machine Learning with Imbalanced Data](https://www.udemy.com/course/machine-learning-with-imbalanced-data/?referralCode=F30537642DA57D19ED83) - Online Course"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "course",
   "language": "python",
   "name": "course"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "583px",
    "left": "0px",
    "right": "1324px",
    "top": "107px",
    "width": "212px"
   },
   "toc_section_display": "block",
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
